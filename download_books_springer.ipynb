{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "download books springer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnYiWxDF3krbBU+fJAcX0z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asuskf/download_books_springer/blob/master/download_books_springer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdWMNG2E2Nz5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "beautifulsoup4 = !pip list | grep -i beautifulsoup4\n",
        "googledrivedownloader = !pip list | grep -i googledrivedownloader\n",
        "\n",
        "if len(beautifulsoup4) == 0:\n",
        "  !pip install beautifulsoup4\n",
        "\n",
        "if len(googledrivedownloader) == 0:\n",
        "  !pip install googledrivedownloader\n",
        "  \n",
        "import requests\n",
        "import shutil\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import os\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import re\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1slse7jvELBMwoENYhyiUosKBcLofXpgE',\n",
        "                                      dest_path='/content/libros.csv',\n",
        "                                      unzip=True)\n",
        "\n",
        "def downloadBooks (title, link, tipe):\n",
        "  myBook = urlopen(link)\n",
        "  pageResponse = BeautifulSoup(myBook.read(),\"html5lib\");\n",
        "  filterResponse = [link['href'] for link in pageResponse.findAll('a', href=True) if re.findall(r'pdf$', link['href'])]\n",
        "  url = 'https://link.springer.com'+filterResponse[0]\n",
        "  path_books = '/content/%s'% (tipe)\n",
        "  if not os.path.exists(path_books):\n",
        "    os.mkdir(path_books)\n",
        "  book = requests.get(url, stream=True)\n",
        "  with open('%s' % (path_books+'/'+title.replace(\" \", \"_\").replace(\"/\", \"_\")+'.pdf'), 'wb') as f:\n",
        "    f.write(requests.get(url).content)\n",
        "\n",
        "\n",
        "books = pd.read_csv(\"libros.csv\")\n",
        "type_books = 'Intelligent Technologies and Robotics' #@param ['Behavioral Science and Psychology',  'Religion and Philosophy',  'Intelligent Technologies and Robotics',  'Computer Science',  'Business and Economics',  'Humanities, Social Sciences and Law',  'Energy',  'Mathematics and Statistics',  'Earth and Environmental Science',  'Medicine',  'Economics and Finance',  'Physics and Astronomy',  'Biomedical and Life Sciences',  'Literature, Cultural and Media Studies',  'Engineering',  'Social Sciences',  'Chemistry and Materials Science',  'Business and Management',  'Behavioral Science',  'Education',  'Law and Criminology'] {allow-input: true}\n",
        "leaked_books = books[books['English Package Name'] == type_books]\n",
        "books = dict(zip(leaked_books['Book Title'], leaked_books['OpenURL'].values.tolist()))\n",
        "dowloads = [downloadBooks(title, link, type_books) for title, link in books.items()]\n",
        "shutil.make_archive(type_books, 'zip', '/content/%s'% (type_books))\n",
        "print('Descarga completa')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}